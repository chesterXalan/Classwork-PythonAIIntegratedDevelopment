{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3C017vAjmxqS",
    "outputId": "dabb5fa3-88f6-4d42-a9f8-6ed8f35e63c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:32:10.637438: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-30 11:32:10.653709: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743305530.667296   26947 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743305530.671580   26947 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743305530.684144   26947 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743305530.684167   26947 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743305530.684168   26947 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743305530.684169   26947 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-30 11:32:10.688455: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子: 貓 愛 睡覺 -> 類別: 0\n",
      "句子: 狗 喜歡 跑步 -> 類別: 0\n",
      "句子: 貓 很 可愛 -> 類別: 0\n",
      "句子: 狗 很 忠誠 -> 類別: 0\n",
      "句子: 睡覺 是一種 享受 -> 類別: 0\n",
      "句子: 運動 對健康 有幫助 -> 類別: 1\n",
      "句子: 跑步 是一種 運動 -> 類別: 1\n",
      "句子: 可愛 的 小狗 -> 類別: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743305533.159499   26947 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"貓 愛 睡覺\",\n",
    "    \"狗 喜歡 跑步\",\n",
    "    \"貓 很 可愛\",\n",
    "    \"狗 很 忠誠\",\n",
    "    \"睡覺 是一種 享受\",\n",
    "    \"運動 對健康 有幫助\",\n",
    "    \"跑步 是一種 運動\",\n",
    "    \"可愛 的 小狗\",\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "num_clusters = 2\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(tfidf_array)\n",
    "labels = kmeans.labels_\n",
    "tf_labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"句子: {doc} -> 類別: {tf_labels.numpy()[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bn8XwJzQrNDa",
    "outputId": "e3d2d972-20b4-4700-d61e-2d5d4ad1aca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_matrix\n",
      "   (0, 8)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 9)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 5)\t1\n",
      "  (4, 8)\t1\n",
      "  (4, 6)\t1\n",
      "  (4, 0)\t1\n",
      "  (5, 10)\t1\n",
      "  (5, 3)\t1\n",
      "  (5, 7)\t1\n",
      "  (6, 9)\t1\n",
      "  (6, 6)\t1\n",
      "  (6, 10)\t1\n",
      "  (7, 1)\t1\n",
      "  (7, 4)\t1\n",
      "count_matrix_array\n",
      " [[0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0 1 1]\n",
      " [0 1 0 0 1 0 0 0 0 0 0]]\n",
      "lda_features\n",
      " [[0.74451977 0.25548023]\n",
      " [0.17205978 0.82794022]\n",
      " [0.25531633 0.74468367]\n",
      " [0.73808296 0.26191704]\n",
      " [0.85744139 0.14255861]\n",
      " [0.85574108 0.14425892]\n",
      " [0.18459155 0.81540845]\n",
      " [0.17208144 0.82791856]]\n",
      "句子: 貓 愛 睡覺 -> 類別: 1\n",
      "句子: 狗 喜歡 跑步 -> 類別: 0\n",
      "句子: 貓 很 可愛 -> 類別: 0\n",
      "句子: 狗 很 忠誠 -> 類別: 1\n",
      "句子: 睡覺 是一種 享受 -> 類別: 1\n",
      "句子: 運動 對健康 有幫助 -> 類別: 1\n",
      "句子: 跑步 是一種 運動 -> 類別: 0\n",
      "句子: 可愛 的 小狗 -> 類別: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"貓 愛 睡覺\",\n",
    "    \"狗 喜歡 跑步\",\n",
    "    \"貓 很 可愛\",\n",
    "    \"狗 很 忠誠\",\n",
    "    \"睡覺 是一種 享受\",\n",
    "    \"運動 對健康 有幫助\",\n",
    "    \"跑步 是一種 運動\",\n",
    "    \"可愛 的 小狗\",\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "count_matrix = vectorizer.fit_transform(documents)\n",
    "print(\"count_matrix\\n\", count_matrix)\n",
    "print(\"count_matrix_array\\n\", count_matrix.toarray())\n",
    "num_topics = 2  # 設定兩個主題\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_features = lda_model.fit_transform(count_matrix)\n",
    "print(\"lda_features\\n\", lda_features)\n",
    "kmeans = KMeans(n_clusters=num_topics, random_state=42)\n",
    "kmeans.fit(lda_features)\n",
    "labels = kmeans.labels_\n",
    "tf_labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"句子: {doc} -> 類別: {tf_labels.numpy()[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSAmw3Dexdfx",
    "outputId": "d8e80f66-69ad-489f-8b0d-4494a362deac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子: 貓 喜歡 睡覺 -> 類別: 0\n",
      "句子: 狗 喜歡 跑步 -> 類別: 1\n",
      "句子: 貓 很 可愛 -> 類別: 2\n",
      "句子: 狗 很 忠誠 -> 類別: 3\n",
      "句子: 睡覺 是一種 享受 -> 類別: 4\n",
      "句子: 運動 對健康 有幫助 -> 類別: 5\n",
      "句子: 跑步 是一種 運動 -> 類別: 6\n",
      "句子: 可愛 的 小狗 -> 類別: 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"貓 喜歡 睡覺\",\n",
    "    \"狗 喜歡 跑步\",\n",
    "    \"貓 很 可愛\",\n",
    "    \"狗 很 忠誠\",\n",
    "    \"睡覺 是一種 享受\",\n",
    "    \"運動 對健康 有幫助\",\n",
    "    \"跑步 是一種 運動\",\n",
    "    \"可愛 的 小狗\",\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents).toarray()\n",
    "dbscan = DBSCAN(eps=0.9, min_samples=1, metric=\"euclidean\")  # eps 決定鄰近範圍\n",
    "labels = dbscan.fit_predict(tfidf_matrix)\n",
    "tf_labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"句子: {doc} -> 類別: {tf_labels.numpy()[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MfQiplSqvmM",
    "outputId": "53aad4ee-3ed1-4127-e51d-5468cdf799dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子: 貓 喜歡 睡覺 -> 類別: 1\n",
      "句子: 狗 喜歡 跑步 -> 類別: 0\n",
      "句子: 貓 很 可愛 -> 類別: 0\n",
      "句子: 狗 很 忠誠 -> 類別: 0\n",
      "句子: 睡覺 是一種 享受 -> 類別: 1\n",
      "句子: 運動 對健康 有幫助 -> 類別: 1\n",
      "句子: 慢跑 是一種 運動 -> 類別: 0\n",
      "句子: 可愛 的 小狗 -> 類別: 0\n",
      "[[3.15503443e-031 1.00000000e+000]\n",
      " [1.00000000e+000 6.95444741e-096]\n",
      " [1.00000000e+000 6.94844544e-084]\n",
      " [1.00000000e+000 4.19737756e-082]\n",
      " [4.19296289e-039 1.00000000e+000]\n",
      " [6.06089439e-039 1.00000000e+000]\n",
      " [1.00000000e+000 1.13798785e-068]\n",
      " [1.00000000e+000 9.60606780e-109]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "documents = [\n",
    "    \"貓 喜歡 睡覺\",\n",
    "    \"狗 喜歡 跑步\",\n",
    "    \"貓 很 可愛\",\n",
    "    \"狗 很 忠誠\",\n",
    "    \"睡覺 是一種 享受\",\n",
    "    \"運動 對健康 有幫助\",\n",
    "    \"慢跑 是一種 運動\",\n",
    "    \"可愛 的 小狗\",\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "count_matrix = vectorizer.fit_transform(documents)\n",
    "num_topics = 2  # 設定兩個主題\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_features = lda_model.fit_transform(count_matrix)\n",
    "gmm = GaussianMixture(n_components=num_topics, random_state=42)\n",
    "gmm.fit(lda_features)\n",
    "labels = gmm.predict(lda_features)\n",
    "tf_labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"句子: {doc} -> 類別: {tf_labels.numpy()[i]}\")\n",
    "proba1 = gmm.predict_proba(lda_features)\n",
    "print(proba1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLrp9qiXekV5",
    "outputId": "ec251b66-b4de-4f41-a8fd-26295fc4f80b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n",
      "'king' 和 'queen' 的相似度: 0.6336\n",
      "\n",
      "與 'king' 最相似的詞:\n",
      "  - queen: 0.6336\n",
      "  - prince: 0.6197\n",
      "  - monarch: 0.5900\n",
      "  - kingdom: 0.5791\n",
      "  - throne: 0.5606\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "glove_model = api.load(\"glove-wiki-gigaword-300\")\n",
    "word1 = \"king\"\n",
    "word2 = \"queen\"\n",
    "if word1 in glove_model and word2 in glove_model:\n",
    "    similarity = glove_model.similarity(word1, word2)\n",
    "    print(f\"'{word1}' 和 '{word2}' 的相似度: {similarity:.4f}\")\n",
    "else:\n",
    "    print(\"詞彙不在 GloVe 詞典中\")\n",
    "similar_words = glove_model.most_similar(\"king\", topn=5)\n",
    "print(\"\\n與 'king' 最相似的詞:\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"  - {word}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHWc4osoesnE",
    "outputId": "71d4efef-8297-41cd-f51f-02d4735557db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "詞彙不在 GloVe 詞典中\n",
      "\n",
      "與 'king' 最相似的詞:\n",
      "  - queen: 0.6336\n",
      "  - prince: 0.6197\n",
      "  - monarch: 0.5900\n",
      "  - kingdom: 0.5791\n",
      "  - throne: 0.5606\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "glove_model = api.load(\"glove-wiki-gigaword-300\")\n",
    "word1 = \"國王\"\n",
    "word2 = \"女王\"\n",
    "if word1 in glove_model and word2 in glove_model:\n",
    "    similarity = glove_model.similarity(word1, word2)\n",
    "    print(f\"'{word1}' 和 '{word2}' 的相似度: {similarity:.4f}\")\n",
    "else:\n",
    "    print(\"詞彙不在 GloVe 詞典中\")\n",
    "similar_words = glove_model.most_similar(\"king\", topn=5)\n",
    "print(\"\\n與 'king' 最相似的詞:\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"  - {word}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vT3BEG4wfbKV",
    "outputId": "ed7e817b-78cf-4f90-cd76-4637e8e628cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.424 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "國王 和 女王 的相似度: 0.1149\n",
      "\n",
      "與 '國王' 最相似的詞:\n",
      "  - 女王: 0.1149\n",
      "  - 強大: 0.1010\n",
      "  - 的: 0.0769\n",
      "  - 是: 0.0574\n",
      "  -  : 0.0477\n",
      "\n",
      "與 '大王' 最相似的詞:\n",
      "  -  : 0.1264\n",
      "  - 統治: 0.1140\n",
      "  - 住: 0.1047\n",
      "  - 公主: 0.0948\n",
      "  - 強大: 0.0806\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from gensim.models import FastText\n",
    "\n",
    "texts = [\"國王 統治 王國\", \"女王 統治 王國\", \"皇帝 是 強大 的\", \"公主 住 在 城堡\"]\n",
    "tokenized_texts = [list(jieba.cut(text)) for text in texts]\n",
    "model = FastText(\n",
    "    sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4, sg=1\n",
    ")\n",
    "model.save(\"fasttext.model\")\n",
    "similarity = model.wv.similarity(\"國王\", \"女王\")\n",
    "print(f\"國王 和 女王 的相似度: {similarity:.4f}\")\n",
    "similar_words = model.wv.most_similar(\"國王\", topn=5)\n",
    "print(\"\\n與 '國王' 最相似的詞:\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"  - {word}: {score:.4f}\")\n",
    "similar_words = model.wv.most_similar(\"大王\", topn=5)\n",
    "print(\"\\n與 '大王' 最相似的詞:\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"  - {word}: {score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
