{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAn0cAsli9G9",
    "outputId": "cb37cf88-32b9-465a-b461-2fc1a602f04e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:34:55.018320: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-30 11:34:55.034470: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743305695.054513   27585 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743305695.058682   27585 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743305695.075612   27585 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743305695.075632   27585 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743305695.075633   27585 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743305695.075634   27585 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-30 11:34:55.079286: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "詞彙表: {'<UNK>': 1, 'deep': 2, 'learning': 3, 'is': 4, 'i': 5, 'love': 6, 'amazing': 7, 'ai': 8, 'the': 9, 'future': 10}\n",
      "數值序列化: [[5, 6, 2, 3], [2, 3, 4, 7], [8, 4, 9, 10]]\n",
      "詞彙表: {'<UNK>': 1, 'deep': 2, 'learning': 3, 'is': 4, 'i': 5, 'love': 6, 'amazing': 7, 'ai': 8, 'the': 9, 'future': 10}\n",
      "數值序列化: [[1, 1, 2, 1], [2, 1, 1, 1], [1, 1, 1, 1]]\n",
      "詞彙表: {'deep': 1, 'learning': 2, 'is': 3, 'i': 4, 'love': 5, 'amazing': 6, 'ai': 7, 'the': 8, 'future': 9}\n",
      "數值序列化: [[1, 2], [1, 2], []]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "texts = [\"I love deep learning\", \"Deep learning is amazing\", \"AI is the future\"]\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "print(\"詞彙表:\", tokenizer.word_index)\n",
    "print(\"數值序列化:\", sequences)\n",
    "tokenizer = Tokenizer(num_words=3, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "print(\"詞彙表:\", tokenizer.word_index)\n",
    "print(\"數值序列化:\", sequences)\n",
    "tokenizer = Tokenizer(num_words=3)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "print(\"詞彙表:\", tokenizer.word_index)\n",
    "print(\"數值序列化:\", sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f7LfhO7oLNb",
    "outputId": "4e75d428-12ae-46b6-c3c2-ccf42cc81256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 4, 1]]\n",
      "[[1, 2, 3]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "texts = [\"I love deep learning\", \"Deep learning is amazing\", \"AI is the future\"]\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "new_texts = [\"Deep learning is awesome\"]\n",
    "new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
    "print(new_sequences)\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "new_texts = [\"Deep learning is awesome\"]\n",
    "new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
    "print(new_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XadzFeKNqAx5",
    "outputId": "c4c81a69-ee00-4b94-a80d-08ab79ecc59e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  1  2  3]\n",
      " [ 4  5  6  7  8]\n",
      " [ 0  0  0  9 10]\n",
      " [12 13 14 15 16]]\n",
      "\n",
      "[[ 1  2  3  0  0]\n",
      " [ 4  5  6  7  8]\n",
      " [ 9 10  0  0  0]\n",
      " [11 12 13 14 15]]\n",
      "\n",
      "[[ 0  0  1  2  3]\n",
      " [ 4  5  6  7  8]\n",
      " [ 0  0  0  9 10]\n",
      " [11 12 13 14 15]]\n",
      "\n",
      "[[ 1  2  3  0  0]\n",
      " [ 4  5  6  7  8]\n",
      " [ 9 10  0  0  0]\n",
      " [12 13 14 15 16]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sequences = [[1, 2, 3], [4, 5, 6, 7, 8], [9, 10], [11, 12, 13, 14, 15, 16]]\n",
    "padded1 = pad_sequences(sequences, maxlen=5, padding=\"pre\", truncating=\"pre\")\n",
    "padded2 = pad_sequences(sequences, maxlen=5, padding=\"post\", truncating=\"post\")\n",
    "padded3 = pad_sequences(sequences, maxlen=5, padding=\"pre\", truncating=\"post\")\n",
    "padded4 = pad_sequences(sequences, maxlen=5, padding=\"post\", truncating=\"pre\")\n",
    "print(padded1)\n",
    "print()\n",
    "print(padded2)\n",
    "print()\n",
    "print(padded3)\n",
    "print()\n",
    "print(padded4)\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
